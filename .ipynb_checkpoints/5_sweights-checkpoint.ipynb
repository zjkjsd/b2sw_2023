{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0986159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48165db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade pip\n",
    "# ! pip install --user numpy scipy matplotlib iminuit boost_histogram sweights pandas uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7b146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import norm, expon, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import ExtendedUnbinnedNLL\n",
    "from iminuit.pdg_format import pdg_format\n",
    "import boost_histogram as bh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee6541",
   "metadata": {},
   "source": [
    "sweights is a package which can implement various different methods for projecting out a particular component in a control variable based on the distribution in a discriminating variable.\n",
    "It is based on the work described in arXiv:2112.04574."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b3bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sweights import SWeight # for classic sweights\n",
    "from sweights import cov_correct, approx_cov_correct # for covariance corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acf783",
   "metadata": {},
   "source": [
    "# Generate toys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d8ca7",
   "metadata": {},
   "source": [
    "We generate toys for an invariant mass and a decay time distribution. The signal model is a Gaussian with mean 0.5 and width 0.1 to describe the mass and an exponential decay with lifetime 0.5. The background is parametrized with a falling exponential distribution with decay constant 1 for the mass and a flat decay time distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79958a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a reproducible seed\n",
    "np.random.seed(21011987)\n",
    "\n",
    "Ns = 5000\n",
    "Nb = 5000\n",
    "ypars = [Ns,Nb]\n",
    "\n",
    "# mass\n",
    "mrange = (0,1)\n",
    "mu = 0.5\n",
    "sg = 0.1\n",
    "lb = 1\n",
    "mpars = [mu,sg,lb]\n",
    "\n",
    "# decay time\n",
    "trange = (0,1)\n",
    "tlb = 2\n",
    "tpars = [tlb]\n",
    "\n",
    "# generate the toy\n",
    "def generate(Ns,Nb,mu,sg,lb,tlb,poisson=False,ret_true=False):\n",
    "\n",
    "    Nsig = np.random.poisson(Ns) if poisson else Ns\n",
    "    Nbkg = np.random.poisson(Nb) if poisson else Nb\n",
    "\n",
    "    sigM = norm(mu,sg)\n",
    "    bkgM = expon(mrange[0], lb)\n",
    "\n",
    "    sigT = expon(trange[0], tlb)\n",
    "    bkgT = uniform(trange[0],trange[1]-trange[0])\n",
    "\n",
    "    # generate\n",
    "    sigMflt = sigM.cdf(mrange)\n",
    "    bkgMflt = bkgM.cdf(mrange)\n",
    "    sigTflt = sigT.cdf(trange)\n",
    "    bkgTflt = bkgT.cdf(trange)\n",
    "\n",
    "    sigMvals = sigM.ppf( np.random.uniform(*sigMflt,size=Nsig) )\n",
    "    sigTvals = sigT.ppf( np.random.uniform(*sigTflt,size=Nsig) )\n",
    "\n",
    "    bkgMvals = bkgM.ppf( np.random.uniform(*bkgMflt,size=Nbkg) )\n",
    "    bkgTvals = bkgT.ppf( np.random.uniform(*bkgTflt,size=Nbkg) )\n",
    "\n",
    "    Mvals = np.concatenate( (sigMvals, bkgMvals) )\n",
    "    Tvals = np.concatenate( (sigTvals, bkgTvals) )\n",
    "\n",
    "    truth = np.concatenate( ( np.ones_like(sigMvals), np.zeros_like(bkgMvals) ) )\n",
    "\n",
    "    if ret_true:\n",
    "        return np.stack( (Mvals,Tvals,truth), axis=1 )\n",
    "    else:\n",
    "        return np.stack( (Mvals,Tvals), axis=1 )\n",
    "\n",
    "toy = generate(Ns,Nb,mu,sg,lb,tlb,ret_true=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaab7cf",
   "metadata": {},
   "source": [
    "# Plot the data and overlay the fit pdfs (without fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful function for plotting data points with error bars\n",
    "def myerrorbar(data, ax, bins, range, wts=None, label=None, col=None):\n",
    "    col = col or 'k'\n",
    "    nh, xe = np.histogram(data,bins=bins,range=range)\n",
    "    cx = 0.5*(xe[1:]+xe[:-1])\n",
    "    err = nh**0.5\n",
    "    if wts is not None:\n",
    "        whist = bh.Histogram( bh.axis.Regular(bins,*range), storage=bh.storage.Weight() )\n",
    "        whist.fill( data, weight = wts )\n",
    "        cx = whist.axes[0].centers\n",
    "        nh = whist.view().value\n",
    "        err = whist.view().variance**0.5\n",
    "\n",
    "    ax.errorbar(cx, nh, err, capsize=2,label=label,fmt=f'{col}o')\n",
    "\n",
    "# define the mass pdf for plotting etc.\n",
    "def mpdf(x, Ns, Nb, mu, sg, lb, comps=['sig','bkg']):\n",
    "\n",
    "    sig  = norm(mu,sg)\n",
    "    sigN = np.diff( sig.cdf(mrange) )\n",
    "\n",
    "    bkg  = expon(mrange[0], lb)\n",
    "    bkgN = np.diff( bkg.cdf(mrange) )\n",
    "\n",
    "    tot = 0\n",
    "    if 'sig' in comps: tot += Ns * sig.pdf(x) / sigN\n",
    "    if 'bkg' in comps: tot += Nb * bkg.pdf(x) / bkgN\n",
    "\n",
    "    return tot\n",
    "\n",
    "# define time pdf for plotting etc.\n",
    "def tpdf(x, Ns, Nb, tlb, comps=['sig','bkg']):\n",
    "\n",
    "    sig  = expon(trange[0],tlb)\n",
    "    sigN = np.diff( sig.cdf(trange) )\n",
    "\n",
    "    bkg  = uniform(trange[0],trange[1]-trange[0])\n",
    "    bkgN = np.diff( bkg.cdf(trange) )\n",
    "\n",
    "    tot = 0\n",
    "    if 'sig' in comps: tot += Ns * sig.pdf(x) / sigN\n",
    "    if 'bkg' in comps: tot += Nb * bkg.pdf(x) / bkgN\n",
    "\n",
    "    return tot\n",
    "\n",
    "# define plot function\n",
    "def plot(toy, draw_pdf=True):\n",
    "\n",
    "    nbins = 50\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "    myerrorbar(toy[:,0],ax[0],bins=nbins,range=mrange)\n",
    "    myerrorbar(toy[:,1],ax[1],bins=nbins,range=trange)\n",
    "\n",
    "    if draw_pdf:\n",
    "        m = np.linspace(*mrange,400)\n",
    "        mN = (mrange[1]-mrange[0])/nbins\n",
    "\n",
    "        bkgm = mpdf(m, *(ypars+mpars),comps=['bkg'])\n",
    "        sigm = mpdf(m, *(ypars+mpars),comps=['sig'])\n",
    "        totm = bkgm + sigm\n",
    "\n",
    "        ax[0].plot(m, mN*bkgm, 'r--', label='Background')\n",
    "        ax[0].plot(m, mN*sigm, 'g:' , label='Signal')\n",
    "        ax[0].plot(m, mN*totm, 'b-' , label='Total PDF')\n",
    "\n",
    "        t = np.linspace(*trange,400)\n",
    "        tN = (trange[1]-trange[0])/nbins\n",
    "\n",
    "        bkgt = tpdf(t, *(ypars+tpars),comps=['bkg'])\n",
    "        sigt = tpdf(t, *(ypars+tpars),comps=['sig'])\n",
    "        tott = bkgt + sigt\n",
    "\n",
    "        ax[1].plot(t, tN*bkgt, 'r--', label='Background')\n",
    "        ax[1].plot(t, tN*sigt, 'g:' , label='Signal')\n",
    "        ax[1].plot(t, tN*tott, 'b-' , label='Total PDF')\n",
    "\n",
    "    ax[0].set_xlabel('Invariant mass')\n",
    "    ax[0].set_ylim(bottom=0)\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].set_xlabel('Decay time')\n",
    "    ax[1].set_ylim(bottom=0)\n",
    "    ax[1].legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "plot(toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ff34a",
   "metadata": {},
   "source": [
    "# Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0966727e",
   "metadata": {},
   "source": [
    "The sweight method is only valid for independent variables. We can for example calculate the kendall rank coefficient to test if that is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sweights import kendall_tau # for an independence test\n",
    "from sweights import plot_indep_scatter\n",
    "\n",
    "kts = kendall_tau(toy[:,0],toy[:,1])\n",
    "print('Kendall Tau:', pdg_format( kts[0], kts[1] ) )\n",
    "plot_indep_scatter(toy[:,0],toy[:,1],reduction_factor=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e29d6",
   "metadata": {},
   "source": [
    "# Fit of toy mass distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45403aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mass pdf for iminuit fitting\n",
    "def mpdf_min(x, Ns, Nb, mu, sg, lb):\n",
    "    return (Ns+Nb, mpdf(x, Ns, Nb, mu, sg, lb) )\n",
    "\n",
    "mi = Minuit( ExtendedUnbinnedNLL(toy[:,0], mpdf_min), Ns=Ns, Nb=Nb, mu=mu, sg=sg, lb=lb )\n",
    "mi.limits['Ns'] = (0,Ns+Nb)\n",
    "mi.limits['Nb'] = (0,Ns+Nb)\n",
    "mi.limits['mu'] = mrange\n",
    "mi.limits['sg'] = (0,mrange[1]-mrange[0])\n",
    "mi.limits['lb'] = (0,10)\n",
    "\n",
    "mi.migrad()\n",
    "mi.hesse()\n",
    "display(mi) # only valid for ipython notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f0845",
   "metadata": {},
   "source": [
    "# Construct the sweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83575fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimated functions\n",
    "spdf = lambda m: mpdf(m,*mi.values,comps=['sig'])\n",
    "bpdf = lambda m: mpdf(m,*mi.values,comps=['bkg'])\n",
    "\n",
    "# make the sweighter\n",
    "sweighter = SWeight( toy[:,0], [spdf,bpdf], [mi.values['Ns'],mi.values['Nb']], (mrange,), method='summation', compnames=('sig','bkg'), verbose=True, checks=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c3ac5",
   "metadata": {},
   "source": [
    "# Plot sWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f51458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wts(x, sw, bw, title=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(x, sw, 'b--', label='Signal')\n",
    "    ax.plot(x, bw, 'r:' , label='Background')\n",
    "    ax.plot(x, sw+bw, 'k-', label='Sum')\n",
    "    ax.set_xlabel('Mass')\n",
    "    ax.set_ylabel('Weight')\n",
    "    if title: ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "\n",
    "# plot weights\n",
    "x = np.linspace(*mrange,400)\n",
    "swp = sweighter.get_weight(0,x)\n",
    "bwp = sweighter.get_weight(1,x)\n",
    "plot_wts(x, swp, bwp, 'SW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd9df1",
   "metadata": {},
   "source": [
    "# Use sWeights to perform fit of decay time distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f15802",
   "metadata": {},
   "source": [
    "The minuit fit itself will underestimate the uncertainties so they must be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define weighted nll\n",
    "def wnll(tlb, tdata, wts):\n",
    "    sig  = expon(trange[0],tlb)\n",
    "    sigN = np.diff( sig.cdf(trange) )\n",
    "    return -np.sum( wts * np.log( sig.pdf( tdata ) / sigN ) )\n",
    "\n",
    "# define signal only time pdf for cov corrector\n",
    "def tpdf_cor(x, tlb):\n",
    "    return tpdf(x,1,0,tlb,['sig'])\n",
    "\n",
    "flbs=[]\n",
    "\n",
    "# get the weights\n",
    "wts = sweighter.get_weight(0,toy[:,0])\n",
    "\n",
    "# define the nll\n",
    "nll = lambda tlb: wnll(tlb, toy[:,1], wts)\n",
    "\n",
    "# do the minimisation\n",
    "tmi = Minuit( nll, tlb=tlb )\n",
    "tmi.limits['tlb'] = (1,3)\n",
    "tmi.errordef = Minuit.LIKELIHOOD\n",
    "tmi.migrad()\n",
    "tmi.hesse()\n",
    "\n",
    "# and do the correction\n",
    "fval = np.array(tmi.values)\n",
    "flbs.append(fval[0])\n",
    "fcov = np.array( tmi.covariance.tolist() )\n",
    "\n",
    "# first order correction\n",
    "ncov = approx_cov_correct(tpdf_cor, toy[:,1], wts, fval, fcov, verbose=False)\n",
    "\n",
    "# second order correction\n",
    "hs  = tpdf_cor\n",
    "ws  = lambda m: sweighter.get_weight(0,m)\n",
    "W   = sweighter.Wkl\n",
    "\n",
    "# these derivatives can be done numerically but for the sweights / COW case it's straightfoward to compute them\n",
    "ws = lambda Wss, Wsb, Wbb, gs, gb: (Wbb*gs - Wsb*gb) / ((Wbb-Wsb)*gs + (Wss-Wsb)*gb)\n",
    "dws_Wss = lambda Wss, Wsb, Wbb, gs, gb: gb * ( Wsb*gb - Wbb*gs ) / (-Wss*gb + Wsb*gs + Wsb*gb - Wbb*gs)**2\n",
    "dws_Wsb = lambda Wss, Wsb, Wbb, gs, gb: ( Wbb*gs**2 - Wss*gb**2 ) / (Wss*gb - Wsb*gs - Wsb*gb + Wbb*gs)**2\n",
    "dws_Wbb = lambda Wss, Wsb, Wbb, gs, gb: gs * ( Wss*gb - Wsb*gs ) / (-Wss*gb + Wsb*gs + Wsb*gb - Wbb*gs)**2\n",
    "\n",
    "tcov = cov_correct(hs, [spdf,bpdf], toy[:,1], toy[:,0], wts, [mi.values['Ns'],mi.values['Nb']], fval, fcov, [dws_Wss,dws_Wsb,dws_Wbb],[W[0,0],W[0,1],W[1,1]], verbose=False)\n",
    "print(f'- covariance corrected {fval[0]:.2f} +/- {fcov[0,0]**0.5:.2f} ---> {fval[0]:.2f} +/- {tcov[0,0]**0.5:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5e10c",
   "metadata": {},
   "source": [
    "# Plot the weighted decay distributions and the fit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38837009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweighted(x, wts, wtnames=[], funcs=[]):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    t = np.linspace(*trange,400)\n",
    "    N = (trange[1]-trange[0])/50\n",
    "\n",
    "    for i, wt in enumerate(wts):\n",
    "        label = None\n",
    "        if i<len(wtnames): label = wtnames[i]\n",
    "        myerrorbar(x, ax, bins=50, range=trange, wts=wt, label=label, col=f'C{i}')\n",
    "        if i<len(funcs):\n",
    "            ax.plot(t,N*funcs[i](t),f'C{i}-')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Weighted Events')\n",
    "    fig.tight_layout()\n",
    "\n",
    "swf  = lambda t: tpdf(t, mi.values['Ns'], 0, flbs[0], comps=['sig'] )\n",
    "sws  = sweighter.get_weight(0, toy[:,0])\n",
    "\n",
    "plot_tweighted(toy[:,1], [sws], ['SW'], funcs=[swf] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff456ca4",
   "metadata": {},
   "source": [
    "# Write the sWeights to a root file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74134489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame( )\n",
    "df['mass'] = toy[:,0]\n",
    "df['time'] = toy[:,1]\n",
    "df['sw_sws'] = sweighter.get_weight(0, df['mass'].to_numpy() )\n",
    "df['sw_bws'] = sweighter.get_weight(1, df['mass'].to_numpy() )\n",
    "\n",
    "import uproot\n",
    "\n",
    "with uproot.recreate('outf.root') as f:\n",
    "    f['tree'] = df\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e1f4a",
   "metadata": {},
   "source": [
    "# Custom orthogonal weight functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bd511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sweights import Cow     # for custom orthogonal weight functions\n",
    "\n",
    "# unity\n",
    "Im = 1\n",
    "# sweight equiavlent\n",
    "# Im = lambda m: mpdf(m,*mi.values) / (mi.values['Ns'] + mi.values['Nb'] )\n",
    "\n",
    "# make the cow\n",
    "cw = Cow(mrange, spdf, bpdf, Im, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16af3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meth, cls in zip( ['SW','COW'], [sweighter,cw] ):\n",
    "\n",
    "    # plot weights\n",
    "    x = np.linspace(*mrange,400)\n",
    "    swp = cls.get_weight(0,x)\n",
    "    bwp = cls.get_weight(1,x)\n",
    "    plot_wts(x, swp, bwp, meth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66c6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the weights\n",
    "wts = cw.get_weight(0,toy[:,0])\n",
    "\n",
    "# define the nll\n",
    "nll = lambda tlb: wnll(tlb, toy[:,1], wts)\n",
    "\n",
    "# do the minimisation\n",
    "tmi = Minuit( nll, tlb=tlb )\n",
    "tmi.limits['tlb'] = (1,3)\n",
    "tmi.errordef = Minuit.LIKELIHOOD\n",
    "tmi.migrad()\n",
    "tmi.hesse()\n",
    "\n",
    "# and do the correction\n",
    "fval = np.array(tmi.values)\n",
    "flbs.append(fval[0])\n",
    "fcov = np.array( tmi.covariance.tolist() )\n",
    "\n",
    "# first order correction\n",
    "ncov = approx_cov_correct(tpdf_cor, toy[:,1], wts, fval, fcov, verbose=False)\n",
    "\n",
    "# second order correction\n",
    "hs  = tpdf_cor\n",
    "ws  = lambda m: cw.get_weight(0,m)\n",
    "W   = cw.Wkl\n",
    "\n",
    "# these derivatives can be done numerically but for the sweights / COW case it's straightfoward to compute them\n",
    "ws = lambda Wss, Wsb, Wbb, gs, gb: (Wbb*gs - Wsb*gb) / ((Wbb-Wsb)*gs + (Wss-Wsb)*gb)\n",
    "dws_Wss = lambda Wss, Wsb, Wbb, gs, gb: gb * ( Wsb*gb - Wbb*gs ) / (-Wss*gb + Wsb*gs + Wsb*gb - Wbb*gs)**2\n",
    "dws_Wsb = lambda Wss, Wsb, Wbb, gs, gb: ( Wbb*gs**2 - Wss*gb**2 ) / (Wss*gb - Wsb*gs - Wsb*gb + Wbb*gs)**2\n",
    "dws_Wbb = lambda Wss, Wsb, Wbb, gs, gb: gs * ( Wss*gb - Wsb*gs ) / (-Wss*gb + Wsb*gs + Wsb*gb - Wbb*gs)**2\n",
    "\n",
    "tcov = cov_correct(hs, [spdf,bpdf], toy[:,1], toy[:,0], wts, [mi.values['Ns'],mi.values['Nb']], fval, fcov, [dws_Wss,dws_Wsb,dws_Wbb],[W[0,0],W[0,1],W[1,1]], verbose=False)\n",
    "print(f'- covariance corrected {fval[0]:.2f} +/- {fcov[0,0]**0.5:.2f} ---> {fval[0]:.2f} +/- {tcov[0,0]**0.5:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the weighted decay distributions and the fit result\n",
    "swf  = lambda t: tpdf(t, mi.values['Ns'], 0, flbs[0], comps=['sig'] )\n",
    "cowf = lambda t: tpdf(t, mi.values['Ns'], 0, flbs[1], comps=['sig'] )\n",
    "sws  = sweighter.get_weight(0, toy[:,0])\n",
    "scow = cw.get_weight(0, toy[:,0])\n",
    "\n",
    "plot_tweighted(toy[:,1], [sws,scow], ['SW','COW'], funcs=[swf,cowf] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( )\n",
    "df['mass'] = toy[:,0]\n",
    "df['time'] = toy[:,1]\n",
    "df['sw_sws'] = sweighter.get_weight(0, df['mass'].to_numpy() )\n",
    "df['sw_bws'] = sweighter.get_weight(1, df['mass'].to_numpy() )\n",
    "df['cow_sws'] = cw.get_weight(0, df['mass'].to_numpy() )\n",
    "df['cow_bws'] = cw.get_weight(1, df['mass'].to_numpy() )\n",
    "\n",
    "with uproot.recreate('outf.root') as f:\n",
    "    f['tree'] = df\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457ffec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
